{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d3c92e",
   "metadata": {},
   "source": [
    "# 06 - Continuous Retraining Pipeline\n",
    "\n",
    "**Author:** Hector Carbajal  \n",
    "**Version:** 1.0  \n",
    "**Last Updated:** 2026-02\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "This notebook covers **MLOps maintenance practices**:\n",
    "- **Drift detection**: Monitor feature distributions and model performance\n",
    "- **Retraining triggers**: Automatic model updates when drift is detected\n",
    "- **Model versioning**: Save and track model versions (v001, v002, etc.)\n",
    "- **CI/CD integration**: Update production risk gates with new models\n",
    "\n",
    "## Inputs\n",
    "- Historical training data\n",
    "- New production data (simulated)\n",
    "\n",
    "## Outputs\n",
    "- `models/catboost_classifier_v002.cbm` - Retrained model version\n",
    "- Drift analysis reports\n",
    "\n",
    "## Retraining Trigger Criteria\n",
    "- Feature drift > 15% from historical baseline\n",
    "- Model accuracy drops > 5% from baseline\n",
    "- New data volume threshold reached\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a177600-6216-495a-b42b-67676d98e1bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T06:10:33.084824Z",
     "iopub.status.busy": "2026-02-27T06:10:33.084596Z",
     "iopub.status.idle": "2026-02-27T06:10:34.966361Z",
     "shell.execute_reply": "2026-02-27T06:10:34.965450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded\n",
      "ðŸ“ Project root: /Users/hc/Documents/projects/roku-patch-stability-analytics\n",
      "ðŸ“ Data directory: /Users/hc/Documents/projects/roku-patch-stability-analytics/data/Processed\n",
      "ðŸ“ Model directory: /Users/hc/Documents/projects/roku-patch-stability-analytics/models\n"
     ]
    }
   ],
   "source": [
    "# [1] Setup & Imports\n",
    "# --------------------------------------------------------------------------\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib \n",
    "import sys\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Add project root to path and import config\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parents[0] if current_dir.name == \"notebooks\" else current_dir\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.config import PROCESSED_DATA_DIR, MODELS_DIR, PROJECT_ROOT\n",
    "\n",
    "# For backward compatibility\n",
    "DATA_DIR = PROCESSED_DATA_DIR\n",
    "MODEL_DIR = MODELS_DIR\n",
    "MODEL_PATH = MODEL_DIR / \"catboost_classifier_v001.cbm\"\n",
    "\n",
    "print(f\"âœ… Configuration loaded\")\n",
    "print(f\"ðŸ“ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"ðŸ“ Data directory: {DATA_DIR}\")\n",
    "print(f\"ðŸ“ Model directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18efbdd0-63ba-417f-84f5-43965b8e1fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T06:10:34.968178Z",
     "iopub.status.busy": "2026-02-27T06:10:34.967839Z",
     "iopub.status.idle": "2026-02-27T06:10:34.990634Z",
     "shell.execute_reply": "2026-02-27T06:10:34.989826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created high_risk_flag using threshold: 2835\n",
      "Target distribution in historical data:\n",
      "high_risk_flag\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Historical (Training) Size: 1000 rows\n",
      "New Data Size: 50 rows\n",
      "Combined Retraining Dataset Size: 1050 rows\n",
      "\n",
      "Target distribution for retraining:\n",
      "high_risk_flag\n",
      "0    528\n",
      "1    522\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# [2] Load Historical Data and Simulate New Data Arrival\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --- A. Load Historical (Training) Data ---\n",
    "# This is the original synthetic feature file (simulates your entire historical dataset)\n",
    "historical_df = pd.read_csv(DATA_DIR / \"synthetic_firmware_features.csv\")\n",
    "\n",
    "# Ensure target column is present using 75th percentile threshold (like notebook 03)\n",
    "if 'high_risk_flag' not in historical_df.columns:\n",
    "    # Use 75th percentile threshold (matching notebook 03)\n",
    "    threshold = historical_df['error_rate_per_10k'].quantile(0.75)\n",
    "    historical_df['high_risk_flag'] = (historical_df['error_rate_per_10k'] >= threshold).astype(int)\n",
    "    print(f\"Created high_risk_flag using threshold: {threshold:.0f}\")\n",
    "\n",
    "print(f\"Target distribution in historical data:\")\n",
    "print(historical_df['high_risk_flag'].value_counts())\n",
    "\n",
    "# --- B. Simulate New Data Arrival (New Patches + Known Outcomes) ---\n",
    "# In a real environment, this data would come from the live deployment and monitoring systems\n",
    "# We'll simulate fetching 50 new patch records (with known outcomes)\n",
    "new_data_df = historical_df.sample(n=50, random_state=99).copy()\n",
    "new_data_df['firmware_version'] = new_data_df['firmware_version'].astype(str) + '.NEW'\n",
    "\n",
    "# --- C. Combine for Retraining ---\n",
    "retrain_df = pd.concat([historical_df, new_data_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nHistorical (Training) Size: {historical_df.shape[0]} rows\")\n",
    "print(f\"New Data Size: {new_data_df.shape[0]} rows\")\n",
    "print(f\"Combined Retraining Dataset Size: {retrain_df.shape[0]} rows\")\n",
    "print(f\"\\nTarget distribution for retraining:\")\n",
    "print(retrain_df['high_risk_flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2671692-362c-4b8e-9e6f-eab47a258402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T06:10:34.992833Z",
     "iopub.status.busy": "2026-02-27T06:10:34.992666Z",
     "iopub.status.idle": "2026-02-27T06:10:34.997712Z",
     "shell.execute_reply": "2026-02-27T06:10:34.997165Z"
    }
   },
   "outputs": [],
   "source": "# [3] Drift Analysis and Retraining Trigger Check\n# --------------------------------------------------------------------------\n\n# 1. Check for Population Drift (Feature Change)\n# Compares the mean of the most important feature (code_churn_score)\nhist_mean_churn = historical_df['code_churn_score'].mean()\nhist_std_churn = historical_df['code_churn_score'].std()\nnew_mean_churn = new_data_df['code_churn_score'].mean()\n\n# Calculate drift as percentage change from historical baseline\n# This is more intuitive than standard deviation-based thresholds for business audiences\ndrift_pct = abs(new_mean_churn - hist_mean_churn) / hist_mean_churn * 100 if hist_mean_churn != 0 else 0\nDRIFT_THRESHOLD_PCT = 15.0  # 15% drift triggers retraining\nRETRAIN_TRIGGERED = drift_pct > DRIFT_THRESHOLD_PCT\n\nprint(f\"Historical Mean Churn: {hist_mean_churn:.4f} (std: {hist_std_churn:.4f})\")\nprint(f\"New Data Mean Churn: {new_mean_churn:.4f}\")\nprint(f\"Feature Drift (Churn): {drift_pct:.2f}%\")\n\nif RETRAIN_TRIGGERED:\n    print(f\"\\nðŸš¨ RETRAINING TRIGGERED: (Drift of {drift_pct:.2f}% exceeds threshold of {DRIFT_THRESHOLD_PCT:.1f}%.)\")\nelse:\n    print(f\"\\nâœ… Drift ({drift_pct:.2f}%) within acceptable limits ({DRIFT_THRESHOLD_PCT:.1f}%). No retraining needed.\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b8da4c-5573-4669-9945-75640c00330b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T06:10:34.999589Z",
     "iopub.status.busy": "2026-02-27T06:10:34.999422Z",
     "iopub.status.idle": "2026-02-27T06:10:35.559073Z",
     "shell.execute_reply": "2026-02-27T06:10:35.558284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Retraining complete. New model saved as: catboost_classifier_v002.cbm\n",
      "New model ROC AUC (Holdout Set): 0.8919\n",
      "\n",
      "--- NEXT ACTION: Update CI Gate to load 'catboost_classifier_v002.cbm' ---\n"
     ]
    }
   ],
   "source": [
    "# [4] Model Retraining and Versioning\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "if RETRAIN_TRIGGERED:\n",
    "    \n",
    "    FEATURES = [\n",
    "        \"code_churn_score\",\n",
    "        \"previous_version_error_rate\",\n",
    "        \"avg_device_age_days\",\n",
    "        \"is_hotfix\",\n",
    "        \"patch_security\",\n",
    "    ]\n",
    "    TARGET = \"high_risk_flag\"\n",
    "\n",
    "    # Define X and y for the combined retraining dataset\n",
    "    X_full = retrain_df[FEATURES]\n",
    "    y_full = retrain_df[TARGET]\n",
    "\n",
    "    # Split into train and test sets for honest evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    "    )\n",
    "\n",
    "    # --- Retrain the CatBoost Classifier ---\n",
    "    cbc_v002 = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.01,\n",
    "        loss_function='Logloss',\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    )\n",
    "\n",
    "    cbc_v002.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Versioning and Saving ---\n",
    "    # In a real system, we would increment the version number dynamically\n",
    "    new_model_path = MODEL_DIR / \"catboost_classifier_v002.cbm\"\n",
    "    cbc_v002.save_model(new_model_path)\n",
    "    \n",
    "    # Evaluate on holdout set\n",
    "    test_auc = roc_auc_score(y_test, cbc_v002.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    print(f\"\\nâœ… Retraining complete. New model saved as: {new_model_path.name}\")\n",
    "    print(f\"New model ROC AUC (Holdout Set): {test_auc:.4f}\")\n",
    "\n",
    "    # Update the CI Gate to use the new version in production\n",
    "    print(\"\\n--- NEXT ACTION: Update CI Gate to load 'catboost_classifier_v002.cbm' ---\")\n",
    "else:\n",
    "    print(\"Model version v001 remains active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315bfc6",
   "metadata": {},
   "source": [
    "## Validation Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f9af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T06:10:35.561859Z",
     "iopub.status.busy": "2026-02-27T06:10:35.561686Z",
     "iopub.status.idle": "2026-02-27T06:10:36.459203Z",
     "shell.execute_reply": "2026-02-27T06:10:36.458723Z"
    }
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Create retraining pipeline validation visualizations using ACTUAL computed values\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\nfig.suptitle('Notebook 06 - Continuous Retraining Pipeline Validation', fontsize=16, fontweight='bold')\n\n# 1. Feature Drift Comparison (ACTUAL data from this run)\nfeatures_to_compare = ['code_churn_score', 'previous_version_error_rate', 'avg_device_age_days']\nhist_means = [historical_df[f].mean() for f in features_to_compare]\nnew_means = [new_data_df[f].mean() for f in features_to_compare]\ndrift_pcts = [abs(n - h) / h * 100 if h != 0 else 0 for h, n in zip(hist_means, new_means)]\n\nx = np.arange(len(features_to_compare))\nwidth = 0.35\nbars1 = axes[0, 0].bar(x - width/2, hist_means, width, label='Historical', color='steelblue', alpha=0.8)\nbars2 = axes[0, 0].bar(x + width/2, new_means, width, label='New Data', color='coral', alpha=0.8)\naxes[0, 0].set_xlabel('Feature')\naxes[0, 0].set_ylabel('Mean Value')\naxes[0, 0].set_title('Feature Distribution: Historical vs New Data')\naxes[0, 0].set_xticks(x)\naxes[0, 0].set_xticklabels(['Code Churn', 'Prev Error Rate', 'Device Age'], fontsize=9)\naxes[0, 0].legend()\naxes[0, 0].grid(alpha=0.3, axis='y')\n\n# 2. Drift Percentage by Feature (ACTUAL)\ncolors_drift = ['red' if d > DRIFT_THRESHOLD_PCT else 'green' for d in drift_pcts]\nbars = axes[0, 1].barh(['Code Churn', 'Prev Error Rate', 'Device Age'], drift_pcts, color=colors_drift, edgecolor='black')\naxes[0, 1].axvline(DRIFT_THRESHOLD_PCT, color='red', linestyle='--', linewidth=2, label=f'Threshold: {DRIFT_THRESHOLD_PCT}%')\naxes[0, 1].set_xlabel('Drift (%)')\naxes[0, 1].set_title('Feature Drift Analysis (ACTUAL)')\naxes[0, 1].legend()\nfor bar, pct in zip(bars, drift_pcts):\n    axes[0, 1].text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, f'{pct:.1f}%', va='center', fontsize=10)\n\n# 3. Retraining Decision Summary (ACTUAL from this run)\ndecision_data = {\n    'Drift Detected': 1 if RETRAIN_TRIGGERED else 0,\n    'Model Retrained': 1 if RETRAIN_TRIGGERED else 0,\n    'Version Updated': 1 if RETRAIN_TRIGGERED else 0\n}\ncolors_decision = ['green' if v == 1 else 'lightgray' for v in decision_data.values()]\naxes[0, 2].bar(decision_data.keys(), decision_data.values(), color=colors_decision, edgecolor='black')\naxes[0, 2].set_ylabel('Status (1=Yes, 0=No)')\naxes[0, 2].set_title('Retraining Pipeline Decision (This Run)')\naxes[0, 2].set_ylim([0, 1.5])\n\n# 4. Target Class Distribution Comparison (ACTUAL)\nhist_class_dist = historical_df['high_risk_flag'].value_counts(normalize=True).sort_index()\nnew_class_dist = new_data_df['high_risk_flag'].value_counts(normalize=True).sort_index()\nx = np.arange(2)\nwidth = 0.35\naxes[1, 0].bar(x - width/2, hist_class_dist.values, width, label='Historical', color='steelblue', alpha=0.8)\naxes[1, 0].bar(x + width/2, new_class_dist.values, width, label='New Data', color='coral', alpha=0.8)\naxes[1, 0].set_xlabel('Risk Class')\naxes[1, 0].set_ylabel('Proportion')\naxes[1, 0].set_title('Target Class Distribution Stability')\naxes[1, 0].set_xticks(x)\naxes[1, 0].set_xticklabels(['Low Risk', 'High Risk'])\naxes[1, 0].legend()\n\n# 5. Model Performance (ACTUAL if available)\nif RETRAIN_TRIGGERED and 'test_auc' in dir():\n    # Use actual training performance\n    metrics = {'Train AUC': roc_auc_score(y_train, cbc_v002.predict_proba(X_train)[:, 1]),\n               'Test AUC': test_auc}\n    bars = axes[1, 1].bar(metrics.keys(), metrics.values(), color=['steelblue', 'coral'], edgecolor='black')\n    axes[1, 1].set_ylim([0, 1.0])\n    for bar in bars:\n        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n                       f'{bar.get_height():.3f}', ha='center', fontsize=11, fontweight='bold')\nelse:\n    axes[1, 1].text(0.5, 0.5, 'No retraining performed\\n(drift below threshold)', \n                   ha='center', va='center', transform=axes[1, 1].transAxes, fontsize=12)\naxes[1, 1].set_ylabel('AUC Score')\naxes[1, 1].set_title('Retrained Model Performance')\naxes[1, 1].grid(alpha=0.3, axis='y')\n\n# 6. Data Volume Summary (ACTUAL)\nvolume_data = {\n    'Historical\\nRecords': len(historical_df),\n    'New\\nRecords': len(new_data_df),\n    'Combined\\nTraining': len(retrain_df)\n}\ncolors_vol = ['steelblue', 'coral', 'green']\nbars = axes[1, 2].bar(volume_data.keys(), volume_data.values(), color=colors_vol, edgecolor='black')\naxes[1, 2].set_ylabel('Record Count')\naxes[1, 2].set_title('Data Volume for Retraining')\nfor bar in bars:\n    axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n                   f'{int(bar.get_height()):,}', ha='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Print validation summary using ACTUAL computed values\nprint(\"\\n\" + \"=\"*60)\nprint(\"VALIDATION SUMMARY - Continuous Retraining Pipeline (ACTUAL)\")\nprint(\"=\"*60)\nprint(f\"\\nDrift Analysis:\")\nprint(f\"  Code Churn drift: {drift_pcts[0]:.2f}%\")\nprint(f\"  Prev Error Rate drift: {drift_pcts[1]:.2f}%\")\nprint(f\"  Device Age drift: {drift_pcts[2]:.2f}%\")\nprint(f\"  Threshold: {DRIFT_THRESHOLD_PCT:.1f}%\")\nprint(f\"  Status: {'ðŸš¨ DRIFT DETECTED' if RETRAIN_TRIGGERED else 'âœ… Normal'}\")\nprint(f\"\\nData Volume:\")\nprint(f\"  Historical records: {len(historical_df):,}\")\nprint(f\"  New records: {len(new_data_df):,}\")\nprint(f\"  Combined training set: {len(retrain_df):,}\")\nif RETRAIN_TRIGGERED and 'test_auc' in dir():\n    print(f\"\\nModel Performance (v002):\")\n    print(f\"  Test AUC: {test_auc:.4f}\")\nprint(f\"\\nPipeline Status: {'Retraining completed âœ…' if RETRAIN_TRIGGERED else 'No retraining needed âœ…'}\")\nprint(\"=\"*60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roku-venv",
   "language": "python",
   "name": "roku-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}